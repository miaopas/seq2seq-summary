{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from initialize import *\n",
    "class RNN(Module):\n",
    "    def __init__(self, input_dim, output_dim, hid_dim, activation='linear', return_hidden=False, return_last=False):\n",
    "        super().__init__()  \n",
    "        self.input_ff = nn.Linear(input_dim, hid_dim)\n",
    "        self.hidden_ff = nn.Linear(hid_dim,hid_dim)\n",
    "        self.output_ff = nn.Linear(hid_dim, output_dim)\n",
    "        if activation == 'linear':\n",
    "            self.activation = nn.Identity()\n",
    "        elif activation == 'tanh':\n",
    "            self.activation = nn.Tanh()\n",
    "        else:\n",
    "            raise Exception(\"Unknown activation type\")\n",
    "        self.hid_dim = hid_dim\n",
    "        self.return_hidden = return_hidden\n",
    "        self.return_last = return_last\n",
    "    def forward(self, x, initial_hidden=None):\n",
    "        \n",
    "        #src = [batch size, input len, input dim]\n",
    "        length = x.shape[1]\n",
    "        batch_size = x.shape[0]\n",
    "\n",
    "        hidden = []\n",
    "        # Initial hidden state\n",
    "        if initial_hidden is None:\n",
    "            hidden.append(torch.zeros(batch_size, 1, self.hid_dim, dtype=x.dtype, device=x.device))\n",
    "        else:\n",
    "            hidden.append(initial_hidden)\n",
    "\n",
    "        # input mapping\n",
    "        x = self.input_ff(x)\n",
    "\n",
    "        # recurrent relation\n",
    "        for i in range(length):\n",
    "            h_next = self.activation(x[:,i:i+1,:] + self.hidden_ff(hidden[i]))\n",
    "            hidden.append(h_next)\n",
    "\n",
    "        # Convert all hidden into a tensor\n",
    "        hidden = torch.cat(hidden[1:], dim=1)\n",
    "\n",
    "        # output mapping\n",
    "        out = self.output_ff(hidden)[:,-1,:] if self.return_last else self.output_ff(hidden)\n",
    "\n",
    "        if self.return_hidden:\n",
    "            return out, hidden\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/haruka/Desktop/seq2seq-summary/env/lib/python3.9/site-packages/torch/utils/data/datapipes/utils/common.py:24: UserWarning: Lambda function is not supported for pickle, please use regular python function or functools.partial instead.\n",
      "  warnings.warn(\n",
      "/Users/haruka/Desktop/seq2seq-summary/env/lib/python3.9/site-packages/torch/utils/data/datapipes/iter/selecting.py:54: UserWarning: Lambda function is not supported for pickle, please use regular python function or functools.partial instead.\n",
      "  warnings.warn(\"Lambda function is not supported for pickle, please use \"\n"
     ]
    }
   ],
   "source": [
    "d = torchtext.datasets.WikiText2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filt(string):\n",
    "    if string.strip() == '':\n",
    "        return False\n",
    "    filt = ['=', '<', '>', '[']\n",
    "    for s in string:\n",
    "        if s in filt:\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "\n",
    "l = [string for string in list(iter(d[0]))+list(iter(d[1]))+list(iter(d[2])) if filt(string)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('quotes.txt', 'w', encoding='utf-8') as f:\n",
    "    f.write(''.join(l))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = open('quotes.txt', 'r', encoding='utf-8').read()\n",
    "import string\n",
    "raw_text = ''.join([c for c in text.lower() if c in string.printable])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total chars: 60\n"
     ]
    }
   ],
   "source": [
    "chars = sorted(list(set(raw_text)))\n",
    "print('total chars:', len(chars))\n",
    "char_int = {c: i for i, c in enumerate(chars)}\n",
    "int_char = {i: c for i, c in enumerate(chars)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_chars = len(raw_text)\n",
    "n_vocab = len(chars)\n",
    "seq_length = 100\n",
    "dataX = []\n",
    "dataY = []\n",
    "for i in range(0, n_chars - seq_length, 1):\n",
    "\tseq_in = raw_text[i:i + seq_length]\n",
    "\tseq_out = raw_text[i + seq_length]\n",
    "\tdataX.append([char_int[char] for char in seq_in])\n",
    "\tdataY.append(char_int[seq_out])\n",
    "n_patterns = len(dataX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/Users/haruka/Desktop/seq2seq-summary/temp.ipynb Cell 8'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/haruka/Desktop/seq2seq-summary/temp.ipynb#ch0000017?line=0'>1</a>\u001b[0m dataX\u001b[39m.\u001b[39;49mshape\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "dataX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ff63f0e7bb87ab5ee5b80fab6bdef4004dcebb3d055b4227d9ef2349c12f897b"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
