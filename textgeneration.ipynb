{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/haruka/Workspace/seq2seq-summary/env/bin/python\n"
     ]
    }
   ],
   "source": [
    "from lib.word_generation import *\n",
    "model = WordGeneration(hid_dim=256, num_layers=1, load_data=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'it met with positive sales in japan ,  and was praised by album around who county games out total them run against h final set south released york u such america weeks british support may only million also united only country line university two said international back population february later days group international re side july government south during known between h all number german line football reached water side very became six then weeks population song later where weeks game a . february august before season people made single july british lead league way though games these april season british long central days , episode both use way field highway because '"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict('it met with positive sales in japan ,  and was praised by')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Have 291 of words\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter, defaultdict\n",
    "import numpy as np\n",
    "data_name = 'wiki'\n",
    "with open(f'data/{data_name}.txt', encoding='utf-8') as f:\n",
    "    text = f.read().lower()\n",
    "text = list(filter(lambda x: x!='', text.split(' ')))\n",
    "words = {words for words, count in Counter(text).items() if count >=80}\n",
    "print(f'Have {len(words)} of words')\n",
    "word_indices = defaultdict(lambda:0, {c: i for i, c in enumerate(sorted(words),1)})\n",
    "indices_word = defaultdict(lambda:'', {c: i for i, c in word_indices.items()})\n",
    "maxlen = 100\n",
    "step = 5\n",
    "sentences = []\n",
    "next_word = []\n",
    "for i in range(0, len(text) - maxlen, step):\n",
    "    sentences.append(text[i: i + maxlen])\n",
    "    next_word.append(text[i + maxlen])\n",
    "x = np.zeros((len(sentences)+1, maxlen+1, len(words)+1),dtype=bool)\n",
    "y = np.zeros(len(sentences)+1,dtype=bool)\n",
    "for i, sentence in enumerate(sentences):\n",
    "    for t, word in enumerate(sentence):\n",
    "        x[i, t, word_indices[word]] = 1\n",
    "    y[i] = word_indices[next_word[i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4461580811ecaa8d2658fc25e124c6bfb2f5eb0b671554e73c2a686519281506"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 ('env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
