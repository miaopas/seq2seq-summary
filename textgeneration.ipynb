{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/haruka/Workspace/seq2seq-summary/env/bin/python\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for TextGenerationModel:\n\tsize mismatch for rnn.weight_ih_l0: copying a param with shape torch.Size([512, 65]) from checkpoint, the shape in current model is torch.Size([512, 29]).\n\tsize mismatch for dense.weight: copying a param with shape torch.Size([65, 128]) from checkpoint, the shape in current model is torch.Size([29, 128]).\n\tsize mismatch for dense.bias: copying a param with shape torch.Size([65]) from checkpoint, the shape in current model is torch.Size([29]).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/home/haruka/Workspace/seq2seq-summary/textgeneration.ipynb Cell 1'\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/haruka/Workspace/seq2seq-summary/textgeneration.ipynb#ch0000000?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpl_test\u001b[39;00m \u001b[39mimport\u001b[39;00m TextGenerationModel\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/haruka/Workspace/seq2seq-summary/textgeneration.ipynb#ch0000000?line=1'>2</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/haruka/Workspace/seq2seq-summary/textgeneration.ipynb#ch0000000?line=2'>3</a>\u001b[0m model \u001b[39m=\u001b[39m TextGenerationModel\u001b[39m.\u001b[39;49mload_from_checkpoint(\u001b[39m'\u001b[39;49m\u001b[39mruns/text_generation/version_1/checkpoints/epoch=66-step=116714.ckpt\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "File \u001b[0;32m~/Workspace/seq2seq-summary/env/lib/python3.9/site-packages/pytorch_lightning/core/saving.py:161\u001b[0m, in \u001b[0;36mModelIO.load_from_checkpoint\u001b[0;34m(cls, checkpoint_path, map_location, hparams_file, strict, **kwargs)\u001b[0m\n\u001b[1;32m    <a href='file:///home/haruka/Workspace/seq2seq-summary/env/lib/python3.9/site-packages/pytorch_lightning/core/saving.py?line=157'>158</a>\u001b[0m \u001b[39m# override the hparams with values that were passed in\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/haruka/Workspace/seq2seq-summary/env/lib/python3.9/site-packages/pytorch_lightning/core/saving.py?line=158'>159</a>\u001b[0m checkpoint[\u001b[39mcls\u001b[39m\u001b[39m.\u001b[39mCHECKPOINT_HYPER_PARAMS_KEY]\u001b[39m.\u001b[39mupdate(kwargs)\n\u001b[0;32m--> <a href='file:///home/haruka/Workspace/seq2seq-summary/env/lib/python3.9/site-packages/pytorch_lightning/core/saving.py?line=160'>161</a>\u001b[0m model \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39;49m\u001b[39m.\u001b[39;49m_load_model_state(checkpoint, strict\u001b[39m=\u001b[39;49mstrict, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    <a href='file:///home/haruka/Workspace/seq2seq-summary/env/lib/python3.9/site-packages/pytorch_lightning/core/saving.py?line=161'>162</a>\u001b[0m \u001b[39mreturn\u001b[39;00m model\n",
      "File \u001b[0;32m~/Workspace/seq2seq-summary/env/lib/python3.9/site-packages/pytorch_lightning/core/saving.py:209\u001b[0m, in \u001b[0;36mModelIO._load_model_state\u001b[0;34m(cls, checkpoint, strict, **cls_kwargs_new)\u001b[0m\n\u001b[1;32m    <a href='file:///home/haruka/Workspace/seq2seq-summary/env/lib/python3.9/site-packages/pytorch_lightning/core/saving.py?line=205'>206</a>\u001b[0m model\u001b[39m.\u001b[39mon_load_checkpoint(checkpoint)\n\u001b[1;32m    <a href='file:///home/haruka/Workspace/seq2seq-summary/env/lib/python3.9/site-packages/pytorch_lightning/core/saving.py?line=207'>208</a>\u001b[0m \u001b[39m# load the state_dict on the model automatically\u001b[39;00m\n\u001b[0;32m--> <a href='file:///home/haruka/Workspace/seq2seq-summary/env/lib/python3.9/site-packages/pytorch_lightning/core/saving.py?line=208'>209</a>\u001b[0m keys \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mload_state_dict(checkpoint[\u001b[39m\"\u001b[39;49m\u001b[39mstate_dict\u001b[39;49m\u001b[39m\"\u001b[39;49m], strict\u001b[39m=\u001b[39;49mstrict)\n\u001b[1;32m    <a href='file:///home/haruka/Workspace/seq2seq-summary/env/lib/python3.9/site-packages/pytorch_lightning/core/saving.py?line=210'>211</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m strict:\n\u001b[1;32m    <a href='file:///home/haruka/Workspace/seq2seq-summary/env/lib/python3.9/site-packages/pytorch_lightning/core/saving.py?line=211'>212</a>\u001b[0m     \u001b[39mif\u001b[39;00m keys\u001b[39m.\u001b[39mmissing_keys:\n",
      "File \u001b[0;32m~/Workspace/seq2seq-summary/env/lib/python3.9/site-packages/torch/nn/modules/module.py:1497\u001b[0m, in \u001b[0;36mModule.load_state_dict\u001b[0;34m(self, state_dict, strict)\u001b[0m\n\u001b[1;32m   <a href='file:///home/haruka/Workspace/seq2seq-summary/env/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1491'>1492</a>\u001b[0m         error_msgs\u001b[39m.\u001b[39minsert(\n\u001b[1;32m   <a href='file:///home/haruka/Workspace/seq2seq-summary/env/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1492'>1493</a>\u001b[0m             \u001b[39m0\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mMissing key(s) in state_dict: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m. \u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m   <a href='file:///home/haruka/Workspace/seq2seq-summary/env/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1493'>1494</a>\u001b[0m                 \u001b[39m'\u001b[39m\u001b[39m, \u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin(\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(k) \u001b[39mfor\u001b[39;00m k \u001b[39min\u001b[39;00m missing_keys)))\n\u001b[1;32m   <a href='file:///home/haruka/Workspace/seq2seq-summary/env/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1495'>1496</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(error_msgs) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m-> <a href='file:///home/haruka/Workspace/seq2seq-summary/env/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1496'>1497</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mError(s) in loading state_dict for \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\t\u001b[39;00m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m   <a href='file:///home/haruka/Workspace/seq2seq-summary/env/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1497'>1498</a>\u001b[0m                        \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\t\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mjoin(error_msgs)))\n\u001b[1;32m   <a href='file:///home/haruka/Workspace/seq2seq-summary/env/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1498'>1499</a>\u001b[0m \u001b[39mreturn\u001b[39;00m _IncompatibleKeys(missing_keys, unexpected_keys)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for TextGenerationModel:\n\tsize mismatch for rnn.weight_ih_l0: copying a param with shape torch.Size([512, 65]) from checkpoint, the shape in current model is torch.Size([512, 29]).\n\tsize mismatch for dense.weight: copying a param with shape torch.Size([65, 128]) from checkpoint, the shape in current model is torch.Size([29, 128]).\n\tsize mismatch for dense.bias: copying a param with shape torch.Size([65]) from checkpoint, the shape in current model is torch.Size([29])."
     ]
    }
   ],
   "source": [
    "from pl_test import TextGenerationModel\n",
    "import torch\n",
    "model = TextGenerationModel.load_from_checkpoint('runs/text_generation/version_1/checkpoints/epoch=66-step=116714.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import torch\n",
    "with open('weight.pkl', 'rb') as f:\n",
    "    w = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['lstm/lstm_cell/kernel:0', 'lstm/lstm_cell/recurrent_kernel:0', 'lstm/lstm_cell/bias:0', 'dense/kernel:0', 'dense/bias:0'])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(65, 512)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w['lstm/lstm_cell/kernel:0'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['weight_ih_l0', 'weight_hh_l0', 'bias_ih_l0', 'bias_hh_l0'])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.rnn._parameters.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([65, 512])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.rnn._parameters['weight_ih_l0'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 1, 2, 3])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.convolve([1,2,3,4,5,6], np.array([0,0,0,0,0,1]), mode='same')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "string = str([1,23,4,5,6,6])[1:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1, 23, 4, 5, 6, 6'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1', ' 23', ' 4', ' 5', ' 6', ' 6']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string.strip().split(',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<unknown>, line 1)",
     "output_type": "error",
     "traceback": [
      "Traceback \u001b[0;36m(most recent call last)\u001b[0m:\n",
      "  File \u001b[1;32m~/Workspace/seq2seq-summary/env/lib/python3.9/site-packages/IPython/core/interactiveshell.py:3397\u001b[0m in \u001b[1;35mrun_code\u001b[0m\n    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  Input \u001b[1;32mIn [14]\u001b[0m in \u001b[1;35m<cell line: 2>\u001b[0m\n    ast.literal_eval('1,2,3,,4,5')\n",
      "  File \u001b[1;32m/usr/lib/python3.9/ast.py:62\u001b[0m in \u001b[1;35mliteral_eval\u001b[0m\n    node_or_string = parse(node_or_string, mode='eval')\n",
      "\u001b[0;36m  File \u001b[0;32m/usr/lib/python3.9/ast.py:50\u001b[0;36m in \u001b[0;35mparse\u001b[0;36m\u001b[0m\n\u001b[0;31m    return compile(source, filename, mode, flags,\u001b[0m\n",
      "\u001b[0;36m  File \u001b[0;32m<unknown>:1\u001b[0;36m\u001b[0m\n\u001b[0;31m    1,2,3,,4,5\u001b[0m\n\u001b[0m          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import ast\n",
    "ast.literal_eval('1,2,3,,4,5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1,4,5,1.15,2.1249,3,4,5,1'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.sub(r\"[^0-9.]+\", \",\", '1 4 5  , , 1.15 2.1249 3 4 5 1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.002, 0.022, 0.097, 0.159, 0.097, 0.022, 0.002])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.array([2, 22, 97, 159, 97, 22, 2])/1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4461580811ecaa8d2658fc25e124c6bfb2f5eb0b671554e73c2a686519281506"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 ('env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
