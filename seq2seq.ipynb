{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sequence to Sequence modelling notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from initialize import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=width>\n",
    "\n",
    "### 1. Sequence to sequence modelling tasks\n",
    "\n",
    "Sequence to sequence modelling tasks are machine learning tasks where both the inputs and output are sequences.\n",
    "\n",
    "Some examples:\n",
    "<p align=\"left\">\n",
    "<img src=\"assets/seq_to_seq_applications.png\" alt=\"drawing\" width=\"800\" >\n",
    "</p>\n",
    "\n",
    "Let's first see some examples of sequence to sequence modelling problems.\n",
    "</div>\n",
    "\n",
    "<div class=width>\n",
    "\n",
    "### Examples of sequence to sequence (seq2seq) tasks\n",
    "Let's look at some concrete seq2seq tasks for illustration. \n",
    "\n",
    "#### 1. Shift a sequence\n",
    "This is a toy example where we just shift a sequence to the right, and pad zeros at left. For example we want shift a input by three steps,\n",
    "$$\\begin{align*}\n",
    "\\text{Input:} & \\, 5,8,9,0,1,2,5,6 \\\\\n",
    "\\text{Output:} &\\,  0,0,0,5,8,9,0,1\n",
    "\\end{align*}$$\n",
    "Shifting inputs by $k $ units is actually a linear relation which equivalent to a convolution of the input with a delta impulse,\n",
    "$$\\begin{align*}\n",
    "y(t) = \\sum_s \\delta(s-k)x(t-s)\n",
    "\\end{align*}$$\n",
    "where \n",
    "$$\n",
    "\\delta(s-k) = \\begin{cases}\n",
    "                    1 & s = k \\\\\n",
    "                    0 & \\text{else}\n",
    "                \\end{cases}.\n",
    "$$\n",
    "\n",
    "This relationship is completely determined by the parameter $k$. If can also be considered as the memory of this relationship because we have $y(t) = y(t-k)$. thus when $k$ is large $y(t)$ will depend on a input far from it.\n",
    " \n",
    "Theoretically RNN does not perform well on this task while CNN have very good performance. (See our paper [Approximation Theory of Convolutional Architectures for Time Series Modelling](https://proceedings.mlr.press/v139/jiang21d.html))\n",
    "\n",
    "\n",
    "</div>\n",
    "\n",
    "<style>\n",
    "div.width {\n",
    "\n",
    "    margin:auto;\n",
    "    max-width: 1000px;\n",
    "}\n",
    "</style>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ebf3e3c165e94b82b1813b0c79bdb0ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(HBox(children=(Button(description='Refresh', style=ButtonStyle()),), layout=Layo…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ShiftPlotter(k=25).plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=width>\n",
    "\n",
    "#### 2. Convolution of a sequence\n",
    "Convolution is one of the most basic operation which can be considered as a sequence to sequence task.\n",
    "Suppose $\\bm\\rho$ is a convolution filter, then the convolution of the input $\\bm x$ with the filter is given by\n",
    "$$\\begin{align*}\n",
    "y(t) = \\bm\\rho \\ast\\bm x =\\sum_s \\rho(s)x(t-s).\n",
    "\\end{align*}$$\n",
    "In this case the filter $\\bm \\rho$ determine the relationship.\n",
    "\n",
    "<div>\n",
    "\n",
    "<style>\n",
    "div.width {\n",
    "\n",
    "    margin:auto;\n",
    "    max-width: 1000px;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "295f874da2924ca39eb433d6fc3d7fbc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(Text(value='0.002, 0.022, 0.097, 0.159, 0.097, 0.022, 0.002', description='Filte…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ConvoPlotter().plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=width>\n",
    "\n",
    "#### 3. Lorentz96 System\n",
    "\n",
    "Now let's look at a more complicate example where the input ouput relationship is determined by an nonlinear dynamic system.\n",
    "  \n",
    "  \n",
    "The system have $K$ inputs $\\{x_k\\}$, $K$ outputs $\\{y_k\\}$ and $JK$ hidden variables $\\{z_{j,k}\\}$ with $k = 1, 2, \\dots, K$ and $j = 1, 2, \\dots, J$. The parameters $K,J$ control the number of variables in the system, and can be viewed as a complexity measure.\n",
    "The system satisfies the following dynamics\n",
    "\\begin{align*}\n",
    "    \\frac{dy_k}{dt} & = -y_{k-1}(y_{k-2}-y_{k+1})-y_k + {\\color{green} x_k}  - \\frac{1}{J}\\sum_{j=1}^J z_{j,k},  \\\\\n",
    "    \\frac{dz_{j,k}}{dt} & = -z_{j+1,k}(z_{j+2,k}-z_{j-1,k})-z_{j,k} + y_k.\n",
    "\\end{align*}\n",
    "\n",
    "Thus, given a set of input $\\{x_k\\}$, the systems determins a set of outputs $\\{y_k\\}$.\n",
    "The following plot shows an example with $K=1$, where we have one curve as input, and the system gives an output curve.\n",
    "<div>\n",
    "\n",
    "<style>\n",
    "div.width {\n",
    "\n",
    "    margin:auto;\n",
    "    max-width: 1000px;\n",
    "}\n",
    "</style>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "204a6bd0acc7497a8ca9810177335ff4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(HBox(children=(Button(description='Refresh', style=ButtonStyle()),), layout=Layo…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "LorentzPlotter().plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=width>\n",
    "\n",
    "#### 4. Text Generation\n",
    "\n",
    "This is a real life example for sequence prediction task. Given a begining of a sentence the model will try to write the remaining part. We can generate long paragraphs of articles using this, however,the result may not be meaningful.\n",
    "\n",
    "<div>\n",
    "\n",
    "<style>\n",
    "div.width {\n",
    "\n",
    "    margin:auto;\n",
    "    max-width: 1000px;\n",
    "}\n",
    "</style>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5cc33a8b4c234bd8ab3e41d41d1e401a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(HTML(value=' <font size=\"+1\">Input text: </font>'), Text(value='This is a very g…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "TextGenerator().plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=width>\n",
    "\n",
    "### 2. Baisc Architectures for seq2seq modelling\n",
    "\n",
    "Next let's look at some basic architectures for seq2seq modelling, we will began with recurrent neural work (RNN), which is one of the most simple architectures.\n",
    "</div>\n",
    "\n",
    "<style>\n",
    "div.width {\n",
    "\n",
    "    margin:auto;\n",
    "    max-width: 1000px;\n",
    "}\n",
    "</style>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=width>\n",
    "\n",
    "#### 1.Recurrent neural networks (RNN)\n",
    "\n",
    "Recurrent neural network is the most basic sequence to sequence model. The dynamic can be written as \n",
    "$$\\begin{align*}\n",
    "h_{t+1} &= \\sigma(Wh_{t} + Ux_{t} + b)\\\\\n",
    "o_{t+1} &= c^\\top h_t.\n",
    "\\end{align*}$$ \n",
    "Where $h$ is called the hidden state. Note that this architecture is causal such that the output $o_t$ at time $t$ only depends on inputs up to $t$. \n",
    " \n",
    "<p align=\"center\">\n",
    "<img src=\"assets/rnn.png\" alt=\"drawing\" width=\"500\" >\n",
    "</p>\n",
    "\n",
    "Based on the structure above we can have input output pairs having same length, which is typical supervised learning tasks. We can also feed the output $o_t$ as the input $x_{t+1}$, which forms an autoregressive stucture and are usually applied to time series prediciton  or sequence generation. \n",
    "\n",
    "In the following demo implementation, the model takes a input with size **(batch size, input len, input dim)**, and output having size **(batch size, input len, output dim)**.\n",
    "\n",
    "</div>\n",
    "\n",
    "<style>\n",
    "div.width {\n",
    "\n",
    "    margin:auto;\n",
    "    max-width: 1000px;\n",
    "}\n",
    "</style>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example Implementation\n",
    "class RNN(Module):\n",
    "    def __init__(self,\n",
    "                 input_dim,\n",
    "                 output_dim,\n",
    "                 hid_dim,\n",
    "                 activation=nn.Tanh()\n",
    "                ):\n",
    "        super().__init__()   \n",
    "        self.U = nn.Linear(input_dim, hid_dim)\n",
    "        self.W = nn.Linear(hid_dim,hid_dim)\n",
    "        self.c = nn.Linear(hid_dim, output_dim)\n",
    "        self.hid_dim = hid_dim\n",
    "    def forward(self, x, initial_hidden=None):\n",
    "\n",
    "        #src = [batch size, input len, input dim]\n",
    "        length = x.shape[1]\n",
    "        batch_size = x.shape[0]\n",
    "\n",
    "        hidden = []\n",
    "        # Initial hidden state\n",
    "        if initial_hidden is None:\n",
    "            hidden.append(torch.zeros(batch_size, 1, self.hid_dim, dtype=x.dtype, device=x.device))\n",
    "        else:\n",
    "            hidden.append(initial_hidden)\n",
    "            \n",
    "        # recurrent relation\n",
    "        for i in range(length):\n",
    "            h_next = self.activation(self.W(hidden[i]) + self.U(x)[:,i:i+1,:])\n",
    "            hidden.append(h_next)\n",
    "\n",
    "        # Convert all hidden into a tensor\n",
    "        hidden = torch.cat(hidden[1:], dim=1)\n",
    "\n",
    "        # output mapping\n",
    "        out = self.c(hidden)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=width>\n",
    "\n",
    "Let's now test the model on the tasks we mentioned above. and plot the output against the predictions.\n",
    "\n",
    "</div>\n",
    "\n",
    "<style>\n",
    "div.width {\n",
    "\n",
    "    margin:auto;\n",
    "    max-width: 1000px;\n",
    "}\n",
    "</style>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DCN(Module):\n",
    "    def __init__(self,\n",
    "                 input_dim,\n",
    "                 output_dim,\n",
    "                 hid_dim,\n",
    "                 kernel_size,\n",
    "                 num_layers,\n",
    "                 activation='linear'\n",
    "                ):\n",
    "        super().__init__()\n",
    "        self.conv_layers = nn.ModuleList([nn.Conv1d(hid_dim,hid_dim,kernel_size,padding=(kernel_size-1)*(kernel_size**i),dilation=kernel_size**i,bias=False) for i in range(num_layers)])\n",
    "        self.input_ff = nn.Linear(input_dim, hid_dim)\n",
    "        self.output_ff = nn.Linear(hid_dim, output_dim)\n",
    "        if activation == 'linear':\n",
    "            self.activation = nn.Identity()\n",
    "        elif activation == 'tanh':\n",
    "            self.activation = nn.Tanh()\n",
    "        else:\n",
    "            raise Exception(\"Uknow actication type\")\n",
    "\n",
    "    def forward(self, x):\n",
    "        #src = [batch size, input len, input dim]\n",
    "        length = x.shape[1]\n",
    "        x = self.input_ff(x)\n",
    "\n",
    "        x = x.permute(0,2,1)\n",
    "\n",
    "        for layer in self.conv_layers:\n",
    "            x = x + layer(x)[:,:,:length]\n",
    "       \n",
    "        x = x.permute(0,2,1)\n",
    "\n",
    "        y = self.activation(self.output_ff(x))\n",
    "        return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RNN encoder-decoder\n",
    "\n",
    "Here we introduce the encoder-decoder structure, where we first encodes the input into  the context vector and then decodes the context vector into the output. Suppose both encoder and decoder are RNNs then we can write this relation as \n",
    "$$\n",
    "\\begin{align*}\n",
    "h_s &= \\sigma_E( W_Eh_{s-1}+U_Ex_s+ b_E), \n",
    "    \\hspace{5mm} v = h_\\tau,\\\\\n",
    "     g_t &= \n",
    "     %\\hl{\n",
    "     \\sigma_D( W_Dg_{t-1}+ b_D),\n",
    "     %}\n",
    "    \\hspace{16mm} g_0=v, \\\\\n",
    "    o_t&= \n",
    "    %\\hl{\n",
    "    W_O g_t+b_O.\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "<p align=\"center\">\n",
    "<img src=\"assets/encdec.png\" alt=\"drawing\" width=\"500\" >\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncDec(Module):\n",
    "    def __init__(self,\n",
    "                 input_dim,\n",
    "                 output_dim,\n",
    "                 hid_dim,\n",
    "                 output_len,\n",
    "                 activation='linear'\n",
    "                ):\n",
    "\n",
    "        super().__init__()\n",
    "        self.encoder = RNN(input_dim,output_dim, hid_dim, activation, return_hidden=True)\n",
    "        self.decoder = RNN(input_dim,output_dim, hid_dim, activation)\n",
    "        self.out_len = output_len\n",
    "    def forward(self, x):\n",
    "        _, context = self.encoder(x)\n",
    "        context = context[:,-2:-1,:]\n",
    "        batch_size = x.shape[0]\n",
    "        decoder_input_pad = torch.zeros(batch_size,self.out_len,x.shape[-1], dtype=x.dtype, device=x.device)\n",
    "\n",
    "        y = self.decoder(decoder_input_pad, context)\n",
    "\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_name = f'Shift'\n",
    "\n",
    "train_size = 3000\n",
    "test_size = 500\n",
    "\n",
    "train_dataset = Dataset(*Shift({'path_len':32,'shift': 20}).generate(data_num=train_size), dtype=DTYPE, device=device)\n",
    "test_dataset = Dataset(*Shift({'path_len':32,'shift': 20}).generate(data_num=test_size), dtype=DTYPE, device=device)\n",
    "\n",
    "train_data = torch.utils.data.DataLoader(train_dataset, batch_size=128,drop_last=True)\n",
    "test_data = torch.utils.data.DataLoader(test_dataset, batch_size=128,drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 1,153 trainable parameters\n",
      "Best Valid Loss: 1.95e-05\n"
     ]
    }
   ],
   "source": [
    "experiment_name = f'{data_name}_rnn'\n",
    "rnn = RNN(input_dim=1, output_dim=1, hid_dim=32).double().to(device)\n",
    "rnn.load_state_dict(torch.load(f\"saved_model/{experiment_name}/best_valid.pt\"))\n",
    "rnn.count_parameters()\n",
    "# train_model(name=experiment_name,model=rnn,train_data=train_data, test_data=test_data)\n",
    "print(f'Best Valid Loss: {np.mean(inference(rnn, test_data)):.2e}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 14 trainable parameters\n",
      "Best Valid Loss: 2.28e-32\n"
     ]
    }
   ],
   "source": [
    "experiment_name = f'{data_name}_cnn'\n",
    "cnn = DCN(input_dim=1, output_dim=1, hid_dim=1, kernel_size=2, num_layers=5).double().to(device)\n",
    "cnn.load_state_dict(torch.load(f\"saved_model/{experiment_name}/best_valid.pt\"))\n",
    "cnn.count_parameters()\n",
    "# train_model(name=experiment_name,model=cnn,train_data=train_data, test_data=test_data)\n",
    "print(f'Best Valid Loss: {np.mean(inference(cnn, test_data)):.2e}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Loss: 3.135e-02 \t Val. Loss: 3.129e-02 \t Best Loss: 3.135e-02 \t Current lr: 1.000e-08: | 1000/1000 [06:30<00:00,  2.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Valid Loss: 3.13e-02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "experiment_name = f'{data_name}_encdec'\n",
    "encdec = EncDec(1, 1, hid_dim=64, output_len=32).double().to(device)\n",
    "# encdec.load_state_dict(torch.load(f\"saved_model/{experiment_name}/best_valid.pt\"))\n",
    "train_model(name=experiment_name,model=encdec,train_data=train_data, test_data=test_data)\n",
    "print(f'Best Valid Loss: {np.mean(inference(encdec, test_data)):.2e}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Dataset(X,y , dtype=DTYPE, device='cuda')\n",
    "\n",
    "train_data = torch.utils.data.DataLoader(train_dataset, batch_size=128,drop_last=True)\n",
    "test_data = torch.utils.data.DataLoader(test_dataset, batch_size=128,drop_last=True)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4461580811ecaa8d2658fc25e124c6bfb2f5eb0b671554e73c2a686519281506"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 ('env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
